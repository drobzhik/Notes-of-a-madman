from airflow import DAG
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.operators.python import PythonOperator
from datetime import datetime
import pandas as pd
from pymongo import MongoClient
import logging

def test_connection_postgres():
    hook = PostgresHook(postgres_conn_id='psql_id')
    try:
        conn = hook.get_conn()
        logging.info('PostgreSQL connection successful')
    except Exception as e:
        logging.error(f'PostgreSQL connection failed: {e}')
        raise
    finally:
        conn.close()

def test_connection_mongodb():
    try:
        client = MongoClient()  # Add parameters if needed
        db = client.mydb  # Replace with your database name
        logging.info('MongoDB connection successful')
    except Exception as e:
        logging.error(f'MongoDB connection failed: {e}')
        raise
    finally:
        client.close()

def preprocess_psql_tables():
    hook = PostgresHook(postgres_conn_id='psql_id')
    with hook.get_conn() as conn:
        df_plan = pd.read_sql(sql='SELECT * FROM "план";', con=conn)
        df_tour = pd.read_sql(sql='SELECT * FROM "туризм";', con=conn)

    df_plan = df_plan.drop_duplicates()
    df_tour = df_tour.drop_duplicates()
    df_tour.drop(['заголовок', 'место_публикации', 'пол', 'возраст', 'цитируемость_сми', 'просмотров', 'страна', 'город', 'место', 'текст', 'обработанныи_текст_удалены_эмодзи'], axis=1, inplace=True)
    
    for i in ['аудитория', 'комментариев', 'репостов', 'лаиков', 'вовлеченность', 'дублеи', 'номер_тематического_кластера']:
        df_tour[i] = df_tour[i].apply(lambda x: int(x))

    client = MongoClient()  # Add parameters if needed
    db = client.final  # Replace with your database name
    db['plan'].insert_many(df_plan.to_dict('records'))
    db['tour'].insert_many(df_tour.to_dict('records'))
    client.close()

def preprocess_mongo_tables():
    client = MongoClient()  # Add parameters if needed
    db = client.mydb  # Replace with your database name
    df_stat = pd.DataFrame(list(db['общая_статистика'].find()))
    df_fact = pd.DataFrame(list(db['Факт'].find()))

    df_stat = df_stat.drop_duplicates()
    df_fact = df_fact.drop_duplicates()

    df_fact['_id'] = df_fact['_id'].astype(str)
    df_stat['_id'] = df_stat['_id'].astype(str)
    df_stat = df_stat.drop('', axis=1)

    client = MongoClient()  # Add parameters if needed
    db = client.final  # Replace with your database name
    db['stat'].insert_many(df_stat.to_dict('records'))
    db['fact'].insert_many(df_fact.to_dict('records'))
    client.close()

# Define DAG
with DAG(
    dag_id="test_dag",
    start_date=datetime(2023, 10, 1),
    schedule_interval="@daily",
    catchup=False,
) as dag:

    check_connection_to_postgres = PythonOperator(
        task_id="check_connection_to_postgres",
        python_callable=test_connection_postgres,   
    )

    check_connection_to_mongodb = PythonOperator(
        task_id="check_connection_to_mongodb",
        python_callable=test_connection_mongodb,   
    )

    preprocess_postgres_tables = PythonOperator(
        task_id='preprocess_postgres_tables',
        python_callable=preprocess_psql_tables
    )

    preprocess_mongodb_tables = PythonOperator(
        task_id='preprocess_mongodb_tables',
        python_callable=preprocess_mongo_tables
    )

    # Define task dependencies
    [check_connection_to_postgres, check_connection_to_mongodb] >> preprocess_mongodb_tables >> preprocess_postgres_tables
